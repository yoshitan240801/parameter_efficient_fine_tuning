{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13511,
     "status": "ok",
     "timestamp": 1745805839063,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "L3jus1GOfQLo"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745805839068,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "PZhsJFVwQ9KM"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_TRANSFORM = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                  torchvision.transforms.Normalize(mean=(0.1307,),\n",
    "                                                                                   std=(0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4037,
     "status": "ok",
     "timestamp": 1745805843106,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "5UNjRrXKRMs4",
    "outputId": "483d8d7e-f663-4c07-b3bc-60d368173fdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.6MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 486kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.38MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.81MB/s]\n"
     ]
    }
   ],
   "source": [
    "train_mnist_data = torchvision.datasets.MNIST(root=\"data\",\n",
    "                                              train=True,\n",
    "                                              transform=IMAGE_TRANSFORM,\n",
    "                                              download=True)\n",
    "test_mnist_data = torchvision.datasets.MNIST(root=\"data\",\n",
    "                                             train=False,\n",
    "                                             transform=IMAGE_TRANSFORM,\n",
    "                                             download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1745805843131,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "Hb4zHU9EWvrq",
    "outputId": "f6d8ce8b-41ef-411f-a9b7-4dea772ba9e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "60000\n",
      "<class 'tuple'>\n",
      "2\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 28, 28])\n",
      "<class 'int'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(type(train_mnist_data))  # pytorchのDataSetのようなもの\n",
    "print(len(train_mnist_data))  # (data1, data2, ,,, data60000)\n",
    "print(type(train_mnist_data[0]))\n",
    "print(len(train_mnist_data[0]))  # data1は2つの要素を持つタプル\n",
    "print(type(train_mnist_data[0][0]))\n",
    "print(train_mnist_data[0][0].shape)  # data1の1つ目の要素は画像のテンソル\n",
    "print(type(train_mnist_data[0][1]))\n",
    "print(train_mnist_data[0][1])  # data1の2つ目の要素は正解ラベルの数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1745805843197,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "9ddXNfZHWEy7"
   },
   "outputs": [],
   "source": [
    "# num = 50\n",
    "# fig = plt.figure(figsize=(16, ((num//10)+1)*1.25))\n",
    "# for i in range(50):\n",
    "#     fig.add_subplot(num//10, 10, i+1)\n",
    "#     plt.imshow(X=train_mnist_data[i][0][0], cmap=\"gray\")\n",
    "#     plt.axis(\"off\")\n",
    "# plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1745805843200,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "3UxxRivXZWh7"
   },
   "outputs": [],
   "source": [
    "train_mnist_data_dataloader = torch.utils.data.DataLoader(dataset=train_mnist_data,\n",
    "                                                          batch_size=100,\n",
    "                                                          shuffle=True)\n",
    "test_mnist_data_dataloader = torch.utils.data.DataLoader(dataset=test_mnist_data,\n",
    "                                                         batch_size=100,\n",
    "                                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1745805843203,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "cAhHQtjO370J"
   },
   "outputs": [],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = torch.nn.Linear(in_features=28*28, out_features=1000)\n",
    "        self.layer_2 = torch.nn.Linear(in_features=1000, out_features=2000)\n",
    "        self.layer_3 = torch.nn.Linear(in_features=2000, out_features=10)\n",
    "\n",
    "    def forward(self, in_data):\n",
    "        out_data_layer_1 = torch.nn.functional.relu(input=self.layer_1(input=in_data))\n",
    "        out_data_layer_2 = torch.nn.functional.relu(input=self.layer_2(input=out_data_layer_1))\n",
    "        out_data = self.layer_3(input=out_data_layer_2)\n",
    "        return out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745805843205,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "QCyqSRQw5zNn"
   },
   "outputs": [],
   "source": [
    "nn_model = MyNet().to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1745805843283,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "6HC3yduOZ23-",
    "outputId": "3ec4d84a-ea56-4bfd-d08b-b31776287439"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyNet                                    [100, 10]                 --\n",
       "├─Linear: 1-1                            [100, 1000]               785,000\n",
       "├─Linear: 1-2                            [100, 2000]               2,002,000\n",
       "├─Linear: 1-3                            [100, 10]                 20,010\n",
       "==========================================================================================\n",
       "Total params: 2,807,010\n",
       "Trainable params: 2,807,010\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 280.70\n",
       "==========================================================================================\n",
       "Input size (MB): 0.31\n",
       "Forward/backward pass size (MB): 2.41\n",
       "Params size (MB): 11.23\n",
       "Estimated Total Size (MB): 13.95\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model=nn_model,\n",
    "                  input_size=(100, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60582,
     "status": "ok",
     "timestamp": 1745805903864,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "uiMtPgFCAiRu",
    "outputId": "68e8e97c-216d-4cc1-ba57-02de02e69886"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:00<00:00,  9.90it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=nn_model.parameters(),\n",
    "                             lr=0.001,\n",
    "                             betas=(0.9, 0.999))\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "nn_model.train()\n",
    "# loss_sum = 0\n",
    "for done_minibatch, (image_minibatch, label_minibatch) in tqdm.tqdm(iterable=enumerate(train_mnist_data_dataloader),\n",
    "                                                                    total=len(train_mnist_data_dataloader)):\n",
    "    image_minibatch = image_minibatch.to(device=DEVICE)\n",
    "    label_minibatch = label_minibatch.to(device=DEVICE)\n",
    "    image_minibatch_drop_channel = image_minibatch[:, 0]  # 白黒なのでテンソルのチャネル部分を落とす\n",
    "    image_minibatch_drop_channel_for_linear = image_minibatch_drop_channel.view(-1, 28*28)  # Linear層の入力になるので、縦横を1次元にならす\n",
    "    output = nn_model(in_data=image_minibatch_drop_channel_for_linear)\n",
    "    assert output.shape==(100, 10), \"推論結果は想定する次元数ではない\"\n",
    "    # label_minibatch_for_target = label_minibatch.unsqueeze(dim=1)\n",
    "    # assert label_minibatch_for_target.shape==(100, 1), \"正解ラベルは想定する次元数ではない\"\n",
    "    # loss = loss_f(input=output,\n",
    "    #               target=label_minibatch_for_target)\n",
    "    assert label_minibatch.shape==(100,), \"正解ラベルは想定する次元数ではない\"\n",
    "    loss = loss_f(input=output,\n",
    "                  target=label_minibatch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print(\"{a}回目のミニバッチ学習の損失値：{b}\".format(a=done_minibatch+1, b=loss.item()))\n",
    "#     loss_sum = loss_sum + loss.item()\n",
    "# print(\"損失値の合計：{a}\".format(a=loss_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3831,
     "status": "ok",
     "timestamp": 1745805907697,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "SBu4yNJ2BMDI",
    "outputId": "23a79805-b8a1-4a07-f9d1-0b4ca4cb9d77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率：0.9647\n",
      "画像9で予測が外れた個数：51\n",
      "画像3で予測が外れた個数：26\n",
      "画像2で予測が外れた個数：58\n",
      "画像7で予測が外れた個数：41\n",
      "画像8で予測が外れた個数：15\n",
      "画像5で予測が外れた個数：37\n",
      "画像4で予測が外れた個数：48\n",
      "画像6で予測が外れた個数：17\n",
      "画像0で予測が外れた個数：42\n",
      "画像1で予測が外れた個数：18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nn_model.eval()\n",
    "num_test_data = len(test_mnist_data)\n",
    "num_correct_total = 0\n",
    "num_wrong_total_per_digit = {}\n",
    "with torch.no_grad():\n",
    "    for done_minibatch, (image_minibatch, label_minibatch) in tqdm.tqdm(iterable=enumerate(test_mnist_data_dataloader),\n",
    "                                                                        total=len(test_mnist_data_dataloader)):\n",
    "        image_minibatch = image_minibatch.to(device=DEVICE)\n",
    "        label_minibatch = label_minibatch.to(device=DEVICE)\n",
    "        image_minibatch_drop_channel = image_minibatch[:, 0]\n",
    "        image_minibatch_drop_channel_for_linear = image_minibatch_drop_channel.view(-1, 28*28)\n",
    "        output = nn_model(in_data=image_minibatch_drop_channel_for_linear)\n",
    "        assert output.shape==(100, 10), \"推論結果は想定する次元ではない\"\n",
    "        assert label_minibatch.shape==(100,), \"正解ラベルは想定する次元ではない\"\n",
    "        predict_index = output.argmax(dim=1,\n",
    "                                      keepdim=True)\n",
    "        assert predict_index.shape==(100, 1),  \"推論結果のargmaxが想定する次元ではない\"\n",
    "        for i in range(predict_index.shape[0]):\n",
    "            predict = predict_index[i][0].item()\n",
    "            answer = label_minibatch[i].item()\n",
    "            if predict == answer:\n",
    "                num_correct_total = num_correct_total + 1\n",
    "            else:\n",
    "                if answer not in num_wrong_total_per_digit.keys():\n",
    "                    num_wrong_total_per_digit[answer] = 1\n",
    "                else:\n",
    "                    num_wrong_total_per_digit[answer] = num_wrong_total_per_digit[answer] + 1\n",
    "        # print(\"{a}ミニバッチ完了\".format(a=done_minibatch+1))\n",
    "accuracy = num_correct_total / num_test_data\n",
    "print(\"正解率：{a}\".format(a=accuracy))\n",
    "for k in num_wrong_total_per_digit.keys():\n",
    "    print(\"画像{a}で予測が外れた個数：{b}\".format(a=k, b=num_wrong_total_per_digit[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1745805907728,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "tY-dAA1Cf7QU",
    "outputId": "22500f66-1508-42ae-bdb1-a2f659f09d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2：58個\n"
     ]
    }
   ],
   "source": [
    "# 一番間違いの多かった正解ラベルをピックアップ\n",
    "max_num_wrong_digit = max(num_wrong_total_per_digit,\n",
    "                          key=num_wrong_total_per_digit.get)\n",
    "max_num_wrong = max(num_wrong_total_per_digit.values())\n",
    "print(\"{a}：{b}個\".format(a=max_num_wrong_digit, b=max_num_wrong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qfuh4QztvLE1"
   },
   "source": [
    "$$\n",
    "h = W_0x + \\Delta Wx = W_0x + BAx\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RsHxb4bvb9l"
   },
   "source": [
    "- $h$: 線型結合で更新された重み\n",
    "- $\\Delta Wx$: モデルの重みの更新量\n",
    "- $BAx$: 低ランク分解されたモデルの重みの更新量\n",
    "\t- $B$: $d \\times r$の行列\n",
    "\t- $A$: $r \\times k$の行列\n",
    "\t- ランク$r$を小さく設定し近似することで、パラメータを大幅削減できる\n",
    "    - $A$はランダムなガウシアンノイズで初期化\n",
    "\t- $B$はゼロで初期化\n",
    "\t- $\\Delta W$を$\\frac{\\alpha}{r}$でスケール\n",
    "\t- $\\alpha$は定数で学習率と似ていて学習を安定化させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745805920389,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "tZAnD7C8hE9I"
   },
   "outputs": [],
   "source": [
    "# LoRAを定義\n",
    "class MyLoRA(torch.nn.Module):\n",
    "    def __init__(self, pre_layer_dim, post_layer_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.lora_A = torch.nn.Parameter(data=torch.zeros(size=(rank, post_layer_dim)).to(device=DEVICE))\n",
    "        torch.nn.init.normal_(tensor=self.lora_A,\n",
    "                              mean=0,\n",
    "                              std=1)\n",
    "        assert self.lora_A.shape==(rank, post_layer_dim), \"LoRAのAで想定している次元ではない\"\n",
    "        self.lora_B = torch.nn.Parameter(data=torch.zeros(size=(pre_layer_dim, rank)).to(device=DEVICE))\n",
    "        assert self.lora_B.shape==(pre_layer_dim, rank), \"LoRAのBで想定している次元ではない\"\n",
    "        self.scale = alpha / rank\n",
    "        self.lora_enable_flag = True\n",
    "\n",
    "    def forward(self, original_weight):\n",
    "        if self.lora_enable_flag == True:\n",
    "            delta_W = torch.matmul(input=self.lora_B,\n",
    "                                   other=self.lora_A)\n",
    "            assert delta_W.shape==original_weight.shape, \"LoRAで想定している次元ではない\"\n",
    "            return original_weight + (delta_W * self.scale)\n",
    "        else:\n",
    "            return original_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1745805921544,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "ChcDQrW_x9vy"
   },
   "outputs": [],
   "source": [
    "# 定義したLoRAを呼び出す関数\n",
    "def add_LoRA(layer_for_LoRA, rank, alpha):\n",
    "    pre_dim = layer_for_LoRA.weight.shape[0]\n",
    "    post_dim = layer_for_LoRA.weight.shape[1]\n",
    "    return MyLoRA(pre_layer_dim=pre_dim,\n",
    "                  post_layer_dim=post_dim,\n",
    "                  rank=rank,\n",
    "                  alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1745805922064,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "EpIJwunW8hsN",
    "outputId": "a1691593-df58-4378-9e44-a54b1d11079e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=1000, bias=True)\n",
      "torch.Size([1000, 784])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "print(nn_model.layer_1)\n",
    "print(nn_model.layer_1.weight.shape)\n",
    "print(nn_model.layer_1.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1745805922689,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "-bqMJUJCb-Db",
    "outputId": "5d59b70d-e609-4df8-c661-54fe163742b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametrizedLinear(\n",
       "  in_features=2000, out_features=10, bias=True\n",
       "  (parametrizations): ModuleDict(\n",
       "    (weight): ParametrizationList(\n",
       "      (0): MyLoRA()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register_parametrizationメソッドの引数parametrizationに関数を指定する事で、LoRAを付与する\n",
    "torch.nn.utils.parametrize.register_parametrization(module=nn_model.layer_1,\n",
    "                                                    tensor_name=\"weight\",\n",
    "                                                    parametrization=add_LoRA(layer_for_LoRA=nn_model.layer_1,\n",
    "                                                                             rank=1,\n",
    "                                                                             alpha=1))\n",
    "torch.nn.utils.parametrize.register_parametrization(module=nn_model.layer_2,\n",
    "                                                    tensor_name=\"weight\",\n",
    "                                                    parametrization=add_LoRA(layer_for_LoRA=nn_model.layer_2,\n",
    "                                                                             rank=1,\n",
    "                                                                             alpha=1))\n",
    "torch.nn.utils.parametrize.register_parametrization(module=nn_model.layer_3,\n",
    "                                                    tensor_name=\"weight\",\n",
    "                                                    parametrization=add_LoRA(layer_for_LoRA=nn_model.layer_3,\n",
    "                                                                             rank=1,\n",
    "                                                                             alpha=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1745805923367,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "UWy743qw8k0G",
    "outputId": "f8ef728b-5ba9-49c2-8da2-5291a0bbf9c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParametrizedLinear(\n",
      "  in_features=784, out_features=1000, bias=True\n",
      "  (parametrizations): ModuleDict(\n",
      "    (weight): ParametrizationList(\n",
      "      (0): MyLoRA()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([1000, 784])\n",
      "torch.Size([1000])\n",
      "torch.Size([1, 784])\n",
      "torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(nn_model.layer_1)\n",
    "print(nn_model.layer_1.weight.shape)\n",
    "print(nn_model.layer_1.bias.shape)\n",
    "print(nn_model.layer_1.parametrizations.weight[0].lora_A.shape)\n",
    "print(nn_model.layer_1.parametrizations.weight[0].lora_B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745805923927,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "nQ_aDM0Njcli"
   },
   "outputs": [],
   "source": [
    "# 変数lora_enable_flagをTrueにするとLoRAを加算したモデル(LoRA付き)、FalseにするとLoRAを加算しないモデル(LoRA無しと同じ)\n",
    "# layer_for_LoRA_list = [nn_model.layer_1, nn_model.layer_2, nn_model.layer_3]\n",
    "# for layer_for_LoRA in layer_for_LoRA_list:\n",
    "#     layer_for_LoRA.parametrizations.weight[0].lora_enable_flag = False\n",
    "#     print(layer_for_LoRA.parametrizations.weight[0].lora_enable_flag)\n",
    "#     layer_for_LoRA.parametrizations.weight[0].lora_enable_flag = True\n",
    "#     print(layer_for_LoRA.parametrizations.weight[0].lora_enable_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1745805924813,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "Hlwdo8Z8Y-tk",
    "outputId": "6f843de1-a2fa-4405-97cd-d034f010cf24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyNet                                    [100, 10]                 --\n",
       "├─ParametrizedLinear: 1-1                [100, 1000]               1,000\n",
       "│    └─ModuleDict: 2-1                   --                        --\n",
       "│    │    └─ParametrizationList: 3-1     [1000, 784]               785,784\n",
       "├─ParametrizedLinear: 1-2                [100, 2000]               2,000\n",
       "│    └─ModuleDict: 2-2                   --                        --\n",
       "│    │    └─ParametrizationList: 3-2     [2000, 1000]              2,003,000\n",
       "├─ParametrizedLinear: 1-3                [100, 10]                 10\n",
       "│    └─ModuleDict: 2-3                   --                        --\n",
       "│    │    └─ParametrizationList: 3-3     [10, 2000]                22,010\n",
       "==========================================================================================\n",
       "Total params: 2,813,804\n",
       "Trainable params: 2,813,804\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0\n",
       "==========================================================================================\n",
       "Input size (MB): 0.31\n",
       "Forward/backward pass size (MB): 22.43\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 22.77\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model=nn_model,\n",
    "                  input_size=(100, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1745805925998,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "qc8P4045aj6t",
    "outputId": "8d3f3029-a571-4c3d-d4d7-85cd5d4f054c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新対象(requires_gradがTrue)のパラメータの一覧\n",
      "layer_1.bias：1000個\n",
      "layer_1.parametrizations.weight.original：784000個\n",
      "layer_1.parametrizations.weight.0.lora_A：784個\n",
      "layer_1.parametrizations.weight.0.lora_B：1000個\n",
      "layer_2.bias：2000個\n",
      "layer_2.parametrizations.weight.original：2000000個\n",
      "layer_2.parametrizations.weight.0.lora_A：1000個\n",
      "layer_2.parametrizations.weight.0.lora_B：2000個\n",
      "layer_3.bias：10個\n",
      "layer_3.parametrizations.weight.original：20000個\n",
      "layer_3.parametrizations.weight.0.lora_A：2000個\n",
      "layer_3.parametrizations.weight.0.lora_B：10個\n",
      "更新対象のパラメータの合計数：2813804個\n"
     ]
    }
   ],
   "source": [
    "print(\"更新対象(requires_gradがTrue)のパラメータの一覧\")\n",
    "trainable_total_param_num = 0\n",
    "for model_layer_name, model_layer_parameter in nn_model.named_parameters():\n",
    "    if model_layer_parameter.requires_grad == True:\n",
    "        print(\"{a}：{b}個\".format(a=model_layer_name, b=model_layer_parameter.numel()))\n",
    "        trainable_total_param_num = trainable_total_param_num + model_layer_parameter.numel()\n",
    "print(\"更新対象のパラメータの合計数：{a}個\".format(a=trainable_total_param_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745805926745,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "ni4DPRuagAwD"
   },
   "outputs": [],
   "source": [
    "# LoRAのみを更新対象(requires_gradをTrue)にする\n",
    "for model_layer_name, model_layer_parameter in nn_model.named_parameters():\n",
    "    if \"lora\" not in model_layer_name:\n",
    "        model_layer_parameter.requires_grad = False  # LoRA以外のパラメータは更新対象から外す\n",
    "    else:\n",
    "        model_layer_parameter.requires_grad = True  # LoRAのパラメータは更新対象にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745805927528,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "y36qyZdJN4YM",
    "outputId": "173d5815-3764-4be0-dff9-0dcb23f76718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新対象(requires_gradがTrue)のパラメータの一覧\n",
      "layer_1.parametrizations.weight.0.lora_A：784個\n",
      "layer_1.parametrizations.weight.0.lora_B：1000個\n",
      "layer_2.parametrizations.weight.0.lora_A：1000個\n",
      "layer_2.parametrizations.weight.0.lora_B：2000個\n",
      "layer_3.parametrizations.weight.0.lora_A：2000個\n",
      "layer_3.parametrizations.weight.0.lora_B：10個\n",
      "更新対象のパラメータの合計数：6794個\n"
     ]
    }
   ],
   "source": [
    "print(\"更新対象(requires_gradがTrue)のパラメータの一覧\")\n",
    "trainable_total_param_num = 0\n",
    "for model_layer_name, model_layer_parameter in nn_model.named_parameters():\n",
    "    if model_layer_parameter.requires_grad == True:\n",
    "        print(\"{a}：{b}個\".format(a=model_layer_name, b=model_layer_parameter.numel()))\n",
    "        trainable_total_param_num = trainable_total_param_num + model_layer_parameter.numel()\n",
    "print(\"更新対象のパラメータの合計数：{a}個\".format(a=trainable_total_param_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14389,
     "status": "ok",
     "timestamp": 1745805942855,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "8dbRPD8Ani_v",
    "outputId": "1f23f3cf-911c-465c-d582-fc1639721944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5958\n",
      "5958\n"
     ]
    }
   ],
   "source": [
    "# 訓練データから一番間違いの多かった正解ラベルのみをピックアップ\n",
    "target_digit_row_id_list = [row_id for row_id in range(len(train_mnist_data)) if train_mnist_data[row_id][1] == max_num_wrong_digit]\n",
    "print(len(target_digit_row_id_list))\n",
    "target_digit_train_mnist_data = torch.utils.data.Subset(dataset=train_mnist_data,\n",
    "                                                        indices=target_digit_row_id_list)\n",
    "print(len(target_digit_train_mnist_data))\n",
    "target_digit_train_mnist_data_dataloader = torch.utils.data.DataLoader(dataset=target_digit_train_mnist_data,\n",
    "                                                                       batch_size=100,\n",
    "                                                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9087,
     "status": "ok",
     "timestamp": 1745805951946,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "o1TBDBl1oS7-",
    "outputId": "53992c90-4af0-4814-a90b-c9761ebf9db5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:09<00:00,  6.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# LoRA付きモデルを学習(訓練データは一番間違いの多かった正解ラベルのみ)\n",
    "optimizer = torch.optim.Adam(params=nn_model.parameters(),  # 改めてoptimizerを設定しないとLoRA付きのパラメータを更新してくれない\n",
    "                             lr=0.001,\n",
    "                             betas=(0.9, 0.999))\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "nn_model.train()\n",
    "for done_minibatch, (image_minibatch, label_minibatch) in tqdm.tqdm(iterable=enumerate(target_digit_train_mnist_data_dataloader),\n",
    "                                                                    total=len(target_digit_train_mnist_data_dataloader)):\n",
    "    image_minibatch = image_minibatch.to(device=DEVICE)\n",
    "    label_minibatch = label_minibatch.to(device=DEVICE)\n",
    "    image_minibatch_drop_channel = image_minibatch[:, 0]\n",
    "    image_minibatch_drop_channel_for_linear = image_minibatch_drop_channel.view(-1, 28*28)\n",
    "    output = nn_model(in_data=image_minibatch_drop_channel_for_linear)\n",
    "    loss = loss_f(input=output,\n",
    "                  target=label_minibatch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4588,
     "status": "ok",
     "timestamp": 1745805959215,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "umU5v4mPobPI",
    "outputId": "a1e8d8f4-a1f8-4c8b-92c0-bedeb9875221"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率：0.3766\n",
      "画像7で予測が外れた個数：926\n",
      "画像1で予測が外れた個数：812\n",
      "画像0で予測が外れた個数：969\n",
      "画像6で予測が外れた個数：691\n",
      "画像8で予測が外れた個数：842\n",
      "画像9で予測が外れた個数：856\n",
      "画像5で予測が外れた個数：303\n",
      "画像3で予測が外れた個数：453\n",
      "画像4で予測が外れた個数：380\n",
      "画像2で予測が外れた個数：2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LoRA付きモデルで推論\n",
    "nn_model.eval()\n",
    "num_test_data = len(test_mnist_data)\n",
    "num_correct_total = 0\n",
    "num_wrong_total_per_digit = {}\n",
    "with torch.no_grad():\n",
    "    for done_minibatch, (image_minibatch, label_minibatch) in tqdm.tqdm(iterable=enumerate(test_mnist_data_dataloader),\n",
    "                                                                        total=len(test_mnist_data_dataloader)):\n",
    "        image_minibatch = image_minibatch.to(device=DEVICE)\n",
    "        label_minibatch = label_minibatch.to(device=DEVICE)\n",
    "        image_minibatch_drop_channel = image_minibatch[:, 0]\n",
    "        image_minibatch_drop_channel_for_linear = image_minibatch_drop_channel.view(-1, 28*28)\n",
    "        output = nn_model(in_data=image_minibatch_drop_channel_for_linear)\n",
    "        predict_index = output.argmax(dim=1,\n",
    "                                      keepdim=True)\n",
    "        for i in range(predict_index.shape[0]):\n",
    "            predict = predict_index[i][0].item()\n",
    "            answer = label_minibatch[i].item()\n",
    "            if predict == answer:\n",
    "                num_correct_total = num_correct_total + 1\n",
    "            else:\n",
    "                if answer not in num_wrong_total_per_digit.keys():\n",
    "                    num_wrong_total_per_digit[answer] = 1\n",
    "                else:\n",
    "                    num_wrong_total_per_digit[answer] = num_wrong_total_per_digit[answer] + 1\n",
    "accuracy = num_correct_total / num_test_data\n",
    "print(\"正解率：{a}\".format(a=accuracy))\n",
    "for k in num_wrong_total_per_digit.keys():\n",
    "    print(\"画像{a}で予測が外れた個数：{b}\".format(a=k, b=num_wrong_total_per_digit[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745805962335,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "ABbIYUyYgcXe"
   },
   "outputs": [],
   "source": [
    "# LoRAを初期化\n",
    "layer_for_LoRA_list = [nn_model.layer_1, nn_model.layer_2, nn_model.layer_3]\n",
    "for layer_for_LoRA in layer_for_LoRA_list:\n",
    "    layer_for_LoRA.parametrizations.weight[0].lora_A.data.normal_(mean=0, std=1)\n",
    "    layer_for_LoRA.parametrizations.weight[0].lora_B.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4679,
     "status": "ok",
     "timestamp": 1745805968492,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "VxrTX3MRg9MX",
    "outputId": "9a9dfd4e-db93-40d8-fd07-24760720cae6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 21.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率：0.9647\n",
      "画像9で予測が外れた個数：51\n",
      "画像6で予測が外れた個数：17\n",
      "画像5で予測が外れた個数：37\n",
      "画像8で予測が外れた個数：15\n",
      "画像2で予測が外れた個数：58\n",
      "画像4で予測が外れた個数：48\n",
      "画像0で予測が外れた個数：42\n",
      "画像3で予測が外れた個数：26\n",
      "画像7で予測が外れた個数：41\n",
      "画像1で予測が外れた個数：18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LoRA初期化後のモデルで推論(LoRA無しのモデルと同じ)\n",
    "nn_model.eval()\n",
    "num_test_data = len(test_mnist_data)\n",
    "num_correct_total = 0\n",
    "num_wrong_total_per_digit = {}\n",
    "with torch.no_grad():\n",
    "    for done_minibatch, (image_minibatch, label_minibatch) in tqdm.tqdm(iterable=enumerate(test_mnist_data_dataloader),\n",
    "                                                                        total=len(test_mnist_data_dataloader)):\n",
    "        image_minibatch = image_minibatch.to(device=DEVICE)\n",
    "        label_minibatch = label_minibatch.to(device=DEVICE)\n",
    "        image_minibatch_drop_channel = image_minibatch[:, 0]\n",
    "        image_minibatch_drop_channel_for_linear = image_minibatch_drop_channel.view(-1, 28*28)\n",
    "        output = nn_model(in_data=image_minibatch_drop_channel_for_linear)\n",
    "        predict_index = output.argmax(dim=1,\n",
    "                                      keepdim=True)\n",
    "        for i in range(predict_index.shape[0]):\n",
    "            predict = predict_index[i][0].item()\n",
    "            answer = label_minibatch[i].item()\n",
    "            if predict == answer:\n",
    "                num_correct_total = num_correct_total + 1\n",
    "            else:\n",
    "                if answer not in num_wrong_total_per_digit.keys():\n",
    "                    num_wrong_total_per_digit[answer] = 1\n",
    "                else:\n",
    "                    num_wrong_total_per_digit[answer] = num_wrong_total_per_digit[answer] + 1\n",
    "accuracy = num_correct_total / num_test_data\n",
    "print(\"正解率：{a}\".format(a=accuracy))\n",
    "for k in num_wrong_total_per_digit.keys():\n",
    "    print(\"画像{a}で予測が外れた個数：{b}\".format(a=k, b=num_wrong_total_per_digit[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14201,
     "status": "ok",
     "timestamp": 1745805984354,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "L9hjGeMhhS8s",
    "outputId": "6039fa06-7299-4914-da0c-81955c2ebf57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744\n",
      "744\n"
     ]
    }
   ],
   "source": [
    "# 訓練データから一番間違いの多かった正解ラベルのみの一部をピックアップ\n",
    "target_digit_row_id_list = [row_id for row_id in range(len(train_mnist_data)) if train_mnist_data[row_id][1] == max_num_wrong_digit]\n",
    "random.shuffle(target_digit_row_id_list)\n",
    "part_of_target_digit_row_id_list = target_digit_row_id_list[0:len(target_digit_row_id_list)//8]\n",
    "print(len(part_of_target_digit_row_id_list))\n",
    "target_digit_train_mnist_data = torch.utils.data.Subset(dataset=train_mnist_data,\n",
    "                                                        indices=part_of_target_digit_row_id_list)\n",
    "print(len(target_digit_train_mnist_data))\n",
    "target_digit_train_mnist_data_dataloader = torch.utils.data.DataLoader(dataset=target_digit_train_mnist_data,\n",
    "                                                                       batch_size=100,\n",
    "                                                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1745805986991,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "_DlsLAvlCUFA",
    "outputId": "a9b2c330-52f4-4237-b90d-e0aa05f2f3ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00,  9.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# 改めてLoRA付きモデルを学習(訓練データは一番間違いの多かった正解ラベルのみの一部)\n",
    "optimizer = torch.optim.Adam(params=nn_model.parameters(),  # 改めてoptimizerを設定しないとLoRA付きのパラメータを更新してくれない\n",
    "                             lr=0.001,\n",
    "                             betas=(0.9, 0.999))\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "nn_model.train()\n",
    "for done_minibatch, (image_minibatch, label_minibatch) in tqdm.tqdm(iterable=enumerate(target_digit_train_mnist_data_dataloader),\n",
    "                                                                    total=len(target_digit_train_mnist_data_dataloader)):\n",
    "    image_minibatch = image_minibatch.to(device=DEVICE)\n",
    "    label_minibatch = label_minibatch.to(device=DEVICE)\n",
    "    image_minibatch_drop_channel = image_minibatch[:, 0]\n",
    "    image_minibatch_drop_channel_for_linear = image_minibatch_drop_channel.view(-1, 28*28)\n",
    "    output = nn_model(in_data=image_minibatch_drop_channel_for_linear)\n",
    "    loss = loss_f(input=output,\n",
    "                  target=label_minibatch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5274,
     "status": "ok",
     "timestamp": 1745805994775,
     "user": {
      "displayName": "forML",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "2ak8eU8jC5rI",
    "outputId": "407201c4-3227-4667-fb05-c3d74b1e458f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 19.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率：0.9671\n",
      "画像2で予測が外れた個数：32\n",
      "画像7で予測が外れた個数：47\n",
      "画像0で予測が外れた個数：40\n",
      "画像6で予測が外れた個数：17\n",
      "画像5で予測が外れた個数：40\n",
      "画像4で予測が外れた個数：43\n",
      "画像1で予測が外れた個数：14\n",
      "画像9で予測が外れた個数：50\n",
      "画像8で予測が外れた個数：18\n",
      "画像3で予測が外れた個数：28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 改めてLoRA付きモデルで推論\n",
    "nn_model.eval()\n",
    "num_test_data = len(test_mnist_data)\n",
    "num_correct_total = 0\n",
    "num_wrong_total_per_digit = {}\n",
    "with torch.no_grad():\n",
    "    for done_minibatch, (image_minibatch, label_minibatch) in tqdm.tqdm(iterable=enumerate(test_mnist_data_dataloader),\n",
    "                                                                        total=len(test_mnist_data_dataloader)):\n",
    "        image_minibatch = image_minibatch.to(device=DEVICE)\n",
    "        label_minibatch = label_minibatch.to(device=DEVICE)\n",
    "        image_minibatch_drop_channel = image_minibatch[:, 0]\n",
    "        image_minibatch_drop_channel_for_linear = image_minibatch_drop_channel.view(-1, 28*28)\n",
    "        output = nn_model(in_data=image_minibatch_drop_channel_for_linear)\n",
    "        predict_index = output.argmax(dim=1,\n",
    "                                      keepdim=True)\n",
    "        for i in range(predict_index.shape[0]):\n",
    "            predict = predict_index[i][0].item()\n",
    "            answer = label_minibatch[i].item()\n",
    "            if predict == answer:\n",
    "                num_correct_total = num_correct_total + 1\n",
    "            else:\n",
    "                if answer not in num_wrong_total_per_digit.keys():\n",
    "                    num_wrong_total_per_digit[answer] = 1\n",
    "                else:\n",
    "                    num_wrong_total_per_digit[answer] = num_wrong_total_per_digit[answer] + 1\n",
    "accuracy = num_correct_total / num_test_data\n",
    "print(\"正解率：{a}\".format(a=accuracy))\n",
    "for k in num_wrong_total_per_digit.keys():\n",
    "    print(\"画像{a}で予測が外れた個数：{b}\".format(a=k, b=num_wrong_total_per_digit[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tk-BdPtGLFw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQ973OEatdpZ0F7qJ5WlSX",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
